# Knowledge Graph: Quick Reference

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KNOWLEDGE GRAPH SYSTEM                    â”‚
â”‚                      Two-Stage Pipeline                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: ENTITY RESOLUTION (log_preprocessing.py)          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Input:  "I want to work on it"                             â”‚
â”‚  Output: "Jukka wants to work on the Emi UI"                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Resolve pronouns (I â†’ Jukka)                             â”‚
â”‚  â€¢ Resolve references (it â†’ Emi UI)                         â”‚
â”‚  â€¢ Overlapping chunks (8 msgs + 3 overlap)                  â”‚
â”‚  â€¢ Filter HTML content                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: KNOWLEDGE EXTRACTION (kg_pipeline.py)             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Input:  "Jukka wants to work on the Emi UI"                â”‚
â”‚  Output: [Nodes] Jukka, Emi UI                              â”‚
â”‚          [Edge] Jukka --[WantsToWorkOn]--> Emi UI           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Adaptive windows (20 msgs)                               â”‚
â”‚  â€¢ 7 specialized agents                                      â”‚
â”‚  â€¢ Smart merging                                             â”‚
â”‚  â€¢ Temporal metadata                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Commands

### Run Stage 1 (Entity Resolution)
```python
from app.assistant.kg_core.log_preprocessing import process_unified_log_chunks_with_entity_resolution

result = process_unified_log_chunks_with_entity_resolution(
    chunk_size=8,
    overlap_size=3,
    role_filter=['user', 'assistant']
)
```

### Run Stage 2 (Knowledge Extraction)
```python
from app.assistant.kg_core.kg_pipeline import process_all_processed_entity_logs_to_kg

process_all_processed_entity_logs_to_kg(
    batch_size=100,
    max_batches=20,
    role_filter=['user', 'assistant']
)
```

### Run Both Stages
```bash
# Stage 1
python app/assistant/kg_core/log_preprocessing.py

# Stage 2
python app/assistant/kg_core/kg_pipeline.py
```

## 8 Agents at a Glance

| # | Agent | Stage | Purpose | Input | Output |
|---|-------|-------|---------|-------|--------|
| 1 | **entity_resolver** | 1 | Resolve pronouns & references | Raw text | Resolved text |
| 2 | **conversation_boundary** | 2 | Find conversation breaks | 20 messages | Conversation bounds |
| 3 | **parser** | 2 | Split into atomic sentences | Conversation | Atomic sentences |
| 4 | **fact_extractor** | 2 | Extract nodes & edges | Sentences | Nodes + Edges |
| 5 | **meta_data_add** | 2 | Add temporal metadata | Nodes | Enriched nodes |
| 6 | **node_merger** | 2 | Decide merge vs create | New + Candidates | Merge decision |
| 7 | **node_data_merger** | 2 | Combine node info | Two nodes | Merged data |
| 8 | **edge_merger** | 2 | Decide edge merge | New + Candidates | Merge decision |

## Database Tables

### Stage 1 Tables
```sql
unified_log                    â†’  processed_entity_log
â”œâ”€ id                          â†’  â”œâ”€ id
â”œâ”€ message                     â†’  â”œâ”€ original_message_id (FK)
â”œâ”€ timestamp                   â†’  â”œâ”€ original_sentence
â”œâ”€ role                        â†’  â”œâ”€ resolved_sentence
â”œâ”€ source                      â†’  â”œâ”€ reasoning
â””â”€ processed (bool)            â†’  â”œâ”€ role
                                  â””â”€ processed (bool)
```

### Stage 2 Tables
```sql
nodes                          edges
â”œâ”€ id                          â”œâ”€ id
â”œâ”€ label                       â”œâ”€ source_id (FK â†’ nodes)
â”œâ”€ node_type                   â”œâ”€ target_id (FK â†’ nodes)
â”œâ”€ aliases (array)             â”œâ”€ relationship_type
â”œâ”€ category                    â”œâ”€ relationship_descriptor
â”œâ”€ start_date                  â”œâ”€ sentence
â”œâ”€ end_date                    â”œâ”€ original_message_timestamp
â”œâ”€ start_date_confidence       â”œâ”€ confidence
â”œâ”€ end_date_confidence         â”œâ”€ importance
â”œâ”€ valid_during                â”œâ”€ source
â”œâ”€ semantic_type               â”œâ”€ original_message_id
â”œâ”€ goal_status                 â”œâ”€ sentence_id
â”œâ”€ confidence                  â””â”€ created_at
â”œâ”€ importance
â”œâ”€ hash_tags (array)
â”œâ”€ source
â”œâ”€ original_message_id
â”œâ”€ sentence_id
â”œâ”€ created_at
â””â”€ updated_at
```

## Node Types

| Type | Purpose | Examples | Has Temporal Data? |
|------|---------|----------|-------------------|
| **Entity** | Physical/abstract entities | People, organizations, concepts | No |
| **Event** | Things that happened | "Started project", "Meeting held" | Yes (start/end dates) |
| **Goal** | Objectives/intentions | "Build feature", "Improve UI" | Yes (start/end dates) |
| **State** | Conditions/states | "In development", "Operational" | Yes (valid_during) |
| **Property** | Attributes | "Runs at 9 AM", "User-friendly" | Optional |

## Configuration Cheatsheet

### Stage 1 (Entity Resolution)
```python
CHUNK_SIZE = 8        # Messages per chunk
OVERLAP_SIZE = 3      # Messages to overlap

# Trade-offs:
# Larger chunks    â†’ Better context, slower, more tokens
# Smaller chunks   â†’ Faster, less context, more API calls
# Larger overlap   â†’ Better quality, more duplicates filtered
```

### Stage 2 (Knowledge Extraction)
```python
WINDOW_SIZE = 20           # Total window size
THRESHOLD_POSITION = 15    # Look for breaks past this

# Trade-offs:
# Larger windows     â†’ Better conversation detection, slower
# Smaller windows    â†’ Faster, risk splitting conversations
# Higher threshold   â†’ Prefer future breaks (less conservative)
# Lower threshold    â†’ Prefer past breaks (more conservative)
```

## Monitoring Queries

### Check Processing Status
```sql
-- Stage 1 progress
SELECT 
    COUNT(*) as total,
    SUM(CASE WHEN processed THEN 1 ELSE 0 END) as processed,
    SUM(CASE WHEN NOT processed THEN 1 ELSE 0 END) as remaining
FROM unified_log;

-- Stage 2 progress
SELECT 
    COUNT(*) as total,
    SUM(CASE WHEN processed THEN 1 ELSE 0 END) as processed,
    SUM(CASE WHEN NOT processed THEN 1 ELSE 0 END) as remaining
FROM processed_entity_log;
```

### View Recent Results
```sql
-- Recent nodes
SELECT label, node_type, confidence, importance, created_at 
FROM nodes 
ORDER BY created_at DESC 
LIMIT 20;

-- Recent edges
SELECT 
    n1.label as source,
    e.relationship_type,
    n2.label as target,
    e.confidence,
    e.created_at
FROM edges e
JOIN nodes n1 ON e.source_id = n1.id
JOIN nodes n2 ON e.target_id = n2.id
ORDER BY e.created_at DESC
LIMIT 20;
```

### Graph Statistics
```sql
-- Node type distribution
SELECT node_type, COUNT(*) as count
FROM nodes
GROUP BY node_type
ORDER BY count DESC;

-- Relationship type distribution
SELECT relationship_type, COUNT(*) as count
FROM edges
GROUP BY relationship_type
ORDER BY count DESC;

-- High importance entities
SELECT label, node_type, importance, confidence
FROM nodes
WHERE importance > 0.7
ORDER BY importance DESC, confidence DESC
LIMIT 20;
```

## Common Patterns

### Example 1: Goal Tracking
```sql
-- Find all goals and their status
SELECT 
    label,
    goal_status,
    start_date,
    end_date,
    importance,
    confidence
FROM nodes
WHERE node_type = 'Goal'
ORDER BY importance DESC, start_date DESC;
```

### Example 2: Entity Relationships
```sql
-- Find all of Jukka's relationships
SELECT 
    e.relationship_type,
    n2.label as related_to,
    n2.node_type,
    e.sentence,
    e.created_at
FROM edges e
JOIN nodes n1 ON e.source_id = n1.id
JOIN nodes n2 ON e.target_id = n2.id
WHERE n1.label = 'Jukka'
ORDER BY e.created_at DESC;
```

### Example 3: Temporal Timeline
```sql
-- Events in chronological order
SELECT 
    label,
    start_date,
    end_date,
    valid_during,
    start_date_confidence
FROM nodes
WHERE node_type = 'Event'
  AND start_date IS NOT NULL
ORDER BY start_date ASC;
```

## Troubleshooting Quick Guide

| Issue | Likely Cause | Solution |
|-------|-------------|----------|
| No messages processing | All marked as processed | Check `processed` flags |
| Low quality resolution | Chunk size too small | Increase chunk_size |
| Duplicate entities | Merge threshold too high | Review node_merger agent |
| Missing relationships | Boundary detection splitting | Check conversation_boundary |
| Wrong dates | Timestamp not passed correctly | Verify message_timestamp param |
| Slow processing | LLM API bottleneck | Reduce batch size, check API |

## Performance Benchmarks

### Throughput
- **Stage 1:** ~5-10 messages/second
- **Stage 2:** ~2-5 messages/second
- **Combined:** ~2-4 messages/second (bottleneck)

### Agent Response Times
- entity_resolver: 2-4s
- conversation_boundary: 1-2s
- parser: 1-2s
- fact_extractor: 2-5s
- meta_data_add: 1-3s (per node)
- node_merger: 1-2s
- node_data_merger: 1-2s
- edge_merger: 1-2s

### Bottlenecks
1. ğŸ”´ LLM API calls (main)
2. ğŸŸ¡ Embedding calculations
3. ğŸŸ¢ Database operations (optimized)

## Best Practices

### âœ… DO
- Process in batches (100-200 messages)
- Monitor merge decisions
- Review temporal metadata quality
- Use role_filter to focus on relevant messages
- Check processed flags regularly
- Commit after each window/chunk

### âŒ DON'T
- Process entire log at once (too slow)
- Skip HTML filtering (pollutes graph)
- Ignore confidence/importance scores
- Process without monitoring
- Modify processed flags manually
- Skip entity resolution stage

## Key Metrics to Track

### Quality Metrics
- âœ… Merge rate (should be 20-40%)
- âœ… Confidence scores (average > 0.7)
- âœ… Importance scores (meaningful distribution)
- âœ… Temporal metadata coverage (60-80% for temporal nodes)

### Performance Metrics
- âœ… Processing speed (messages/second)
- âœ… API response times
- âœ… Database commit times
- âœ… Memory usage

### Data Quality
- âœ… Orphaned nodes (should be 0)
- âœ… Duplicate entities (check aliases)
- âœ… Edge connectivity (every node should have edges)
- âœ… Provenance completeness (all nodes have source)

## Pipeline Flow Summary

```
1. READ unprocessed messages from unified_log
   â†“
2. CHUNK into overlapping windows (Stage 1)
   â†“
3. RESOLVE entities with context
   â†“
4. SAVE to processed_entity_log
   â†“
5. MARK original messages as processed
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
6. READ unprocessed sentences from processed_entity_log
   â†“
7. WINDOW into adaptive 20-message windows
   â†“
8. DETECT conversation boundaries
   â†“
9. PARSE into atomic sentences
   â†“
10. EXTRACT facts (nodes + edges)
   â†“
11. ENRICH with metadata
   â†“
12. MERGE with existing knowledge
   â†“
13. COMMIT to graph database
   â†“
14. MARK sentences as processed
```

## Documentation Map

```
README.md                      â† Start here
â”œâ”€ KG_ARCHITECTURE.md          â† System overview
â”œâ”€ KG_ENTITY_RESOLUTION.md     â† Stage 1 details
â”œâ”€ KG_PIPELINE_DETAILS.md      â† Stage 2 details
â”œâ”€ KG_AGENTS.md                â† All 8 agents
â””â”€ KG_QUICK_REFERENCE.md       â† This file!
```

## Getting Help

1. **Read the docs** - Start with README.md
2. **Check logs** - Detailed output shows decisions
3. **Test small batch** - Isolate issues
4. **Review queries** - Verify data quality
5. **Contact team** - If still stuck

---

**Quick Links:**
- [Full Architecture](./KG_ARCHITECTURE.md)
- [Entity Resolution](./KG_ENTITY_RESOLUTION.md)
- [Pipeline Details](./KG_PIPELINE_DETAILS.md)
- [Agent Details](./KG_AGENTS.md)
- [Main README](./README.md)

**Last Updated:** September 29, 2025
